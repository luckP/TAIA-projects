{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.datasets import make_classification\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos a biblioteca do pandas para fazer a leitura dos dados que se encontram dentro do ficheiro data.csv.\n",
    "Contendo neste ficheiro os dados registados nos pacientes com cancro.<br>\n",
    "Foi feito um ligeiro tratamento de dados, retirando da tabela na coluna id algumas linhas no ficheiro que continha valores Unnamed e transformando os valores da coluna diagnosis, que continham os valores M e B que correspondiam respetivamente maligno e benigno, para o formato 0 e 1, passando os valores malignos para 0 e benignos para 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df = df.drop(['id', 'Unnamed: 32'], axis=1)\n",
    "df.diagnosis = df.diagnosis.transform(lambda x: 0 if x == 'M' else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = df.columns\n",
    "x = df.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df = pd.DataFrame(x_scaled, columns=col)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação dos dados em treino e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi feito uma separação dos dados sendo os dados separados em dados de testes e de treino. Sendo colocados como argumento os valores das colunas sem ser a do diagnosis e somente a coluna diagnosis e tendo como tamanho do texto igual a 0.3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separated the class variable 'y' and the others variables\n",
    "y = df.diagnosis.values\n",
    "X = df.drop(['diagnosis'], axis=1).values\n",
    "\n",
    "# Separate test and training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi utilizado uma svm com kernel linear da livraria sklearn.svm.<br>\n",
    "Os resultados foram bastante positivos tendo em media uma accuracy **XXXXXXXXxxx** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "c = 0\n",
    "for i in range(len(pred)):\n",
    "    if(y_test[i] == pred[i]):\n",
    "        c+=1\n",
    "        \n",
    "print((c/len(pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi utilizado uma randomforest tendo a profundidade maxima de 2 e o random_state 0 e foi importado da livraria sklearn.ensemble import RandomForestClassifier.\n",
    "<br>\n",
    "Os resultados foram bastante positivos tendo em media uma accuracy \n",
    "**XXXXXXXXxxx** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "c = 0\n",
    "for i in range(len(pred)):\n",
    "    if(y_test[i] == pred[i]):\n",
    "        c+=1\n",
    "\n",
    "print((c/len(pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi utilizado uma decisiontree e foi importado da livraria sklearn import tree.\n",
    "<br>\n",
    "Os resultados foram bastante positivos tendo em media uma accuracy \n",
    "**XXXXXXXXxxx** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "c = 0\n",
    "for i in range(len(pred)):\n",
    "    if(y_test[i] == pred[i]):\n",
    "        c+=1\n",
    "\n",
    "print((c/len(pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KERAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi utilizado o modelo sequential para a criação do deep network, sendo esse modelo um conjunto linear de camadas.<br>\n",
    "Adcionamos 6 camadas ao modelo, tendo como activação o relu que serve como uma boa base de criação de uma deep network em cinco dessas camadas, e utilizamos valores de neurônios alternados tendo no maximo 50, porque o nosso dataset não continha uma grande quantidade de dados. No ultimo neurônio utilizamos a função de probabilidade softmax \n",
    "## Incompleto fazer testes com outros activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criar o modelo de forma sequencial\n",
    "model = Sequential()\n",
    "# train_y = to_categorical(df.High)\n",
    "\n",
    "#apanhar o numero de colunas no training data\n",
    "n_cols = len(df.columns) -1\n",
    "\n",
    "#adicionar camadas ao modelo\n",
    "model.add(Dense(30, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilamos o modelo utilizando o adam como o optimizer, tendo como função de loss o mean_squared_error e utilizamos como metrica a accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compilar o modelo usando accuracy para medir a performance\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colocamos um monitor earlystopping para que o modelo parasse quando via que não poderia melhorar, evitando assim overfit.<br>\n",
    "Treinamos o modelo com as dataset de treino x e y normalizadas definidos anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set early stopping monitor so the model stops training when it won't improve anymore\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "#treinar o modelo\n",
    "\n",
    "m=model.fit(X_train, y_train, validation_split=0.2, epochs=30)# callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como constatado pelos testes feitos utilizando com os diferentes modelos de machine learning, o modelo que teve a melhor performance foi **XXXXXXXXXXXXXXXXXXXXX** e o pior modelo foi o do deep learning.<br>\n",
    "Acreditamos que o modelo de deep learning não teve grande exito por termos usado um dataset com muito poucos dados, sendo o deep learning mas efectivo em datasets com uma grande quantidade de dados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yasssssss\n"
     ]
    }
   ],
   "source": [
    "print (\"yasssssss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
