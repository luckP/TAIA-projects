{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No âmbito da cadeira de Tópicos Avançado em Inteligência Artificial foi nos propostos fazer um trabalho em que o objetivo era comparar a tecnologia do deep network num dataset, para ver qual técnicas seriam úteis e para saber como funciona a sua pesquisa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos a biblioteca do pandas para fazer a leitura dos dados que se encontram dentro do ficheiro data.csv.\n",
    "Contendo neste ficheiro os dados registados nos pacientes com cancro.<br>\n",
    "Foi feito um ligeiro tratamento de dados, retirando da tabela na coluna id algumas linhas no ficheiro que continha valores Unnamed, e também foi transformando os valores da coluna diagnosis, que continham os valores M e B que correspondiam respetivamente maligno e benigno, para o formato 0 e 1, passando os valores malignos para 0 e benignos para 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df = df.drop(['id', 'Unnamed: 32'], axis=1)\n",
    "df.diagnosis = df.diagnosis.transform(lambda x: 0 if x == 'M' else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = df.columns\n",
    "x = df.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df = pd.DataFrame(x_scaled, columns=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação dos dados em treino e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi feito uma separação dos dados sendo os dados separados em X_train e y_train, que são os dados que serão utilizados para treinar os vários modelos que irão ser utilizados, e X_test e y_test, que serão os dados que serão utilizados para fazer o teste dos vários modelos para poder saber a performance de cada um.<br>\n",
    "Sendo colocados nas variaveis X_train e X_test os valores do dataset sem a coluna diagnosis, e nas variáveis y_train e y_test somente os valores da coluna diagnosis que será a coluna que queremos descobrir o resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.diagnosis.values\n",
    "X = df.drop(['diagnosis'], axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi utilizado uma svm com kernel linear da biblioteca sklearn.svm.<br>\n",
    "Os resultados foram bastante positivos tendo uma accuracy superior a 95%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.24561403508771\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "c = 0\n",
    "for i in range(len(pred)):\n",
    "    if(y_test[i] == pred[i]):\n",
    "        c+=1\n",
    "        \n",
    "print((c/len(pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi utilizado uma randomforest tendo a profundidade maxima de 2 e o random_state 0 e foi importado da biblioteca sklearn.ensemble import RandomForestClassifier.\n",
    "<br>\n",
    "Os resultados foram também positivos, tendo uma accuracy superior a 91%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.15204678362574\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "c = 0\n",
    "for i in range(len(pred)):\n",
    "    if(y_test[i] == pred[i]):\n",
    "        c+=1\n",
    "\n",
    "print((c/len(pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi utilizado uma decision tree e foi importado da biblioteca sklearn import tree.\n",
    "<br>\n",
    "Os resultados foram bastante bons embora tenha sido o modelo com menor performance do que os valores anteriores tendo uma accuracy superior a 89%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.98245614035088\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "c = 0\n",
    "for i in range(len(pred)):\n",
    "    if(y_test[i] == pred[i]):\n",
    "        c+=1\n",
    "\n",
    "print((c/len(pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KERAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi utilizado o modelo sequential para a criação do deep network, sendo esse modelo um conjunto linear de camadas.\n",
    "<br>\n",
    "Adicionamos 6 camadas ao modelo, como a função relu serve de uma boa base de criação de uma deep network começamos no inicio com ela, no fim fizemos alguns testes com a função de sigmoid,tanh e LeakyRelu mas como a performance não melhorou e em alguns casos demora mais tempo para construir o modelo, resolvemos continuar com o relu como função de ativação do nosso modelo, em cinco camadas das 6. Utilizamos valores de neurónios alternados tendo no máximo 50, porque o nosso dataset não continha uma grande quantidade de dados por isso achamos não ser necessários possuir tantos neurónios.<br>\n",
    "No último neurónio utilizamos a função de probabilidade softmax porque foi a nossa função escolhida inicialmente e a performance não melhorou em relação as outras funções de probabilidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "model = Sequential()\n",
    "# train_y = to_categorical(df.High)\n",
    "\n",
    "n_cols = len(df.columns) -1\n",
    "\n",
    "model.add(Dense(30, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilamos o modelo utilizando o adam como o optimizer, tendo como função de loss o mean_squared_error e utilizamos como métrica a accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colocamos um monitor earlystopping para que o modelo parasse quando via que não poderia melhorar, evitando assim overfit.<br>\n",
    "Treinamos o modelo com as dataset de treino X_train e y_train definidos nos passos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 318 samples, validate on 80 samples\n",
      "Epoch 1/30\n",
      "318/318 [==============================] - 0s 79us/step - loss: 0.3553 - accuracy: 0.6447 - val_loss: 0.3500 - val_accuracy: 0.6500\n",
      "Epoch 2/30\n",
      "318/318 [==============================] - 0s 95us/step - loss: 0.3553 - accuracy: 0.6447 - val_loss: 0.3500 - val_accuracy: 0.6500\n",
      "Epoch 3/30\n",
      "318/318 [==============================] - 0s 74us/step - loss: 0.3553 - accuracy: 0.6447 - val_loss: 0.3500 - val_accuracy: 0.6500\n",
      "Epoch 4/30\n",
      "318/318 [==============================] - 0s 87us/step - loss: 0.3553 - accuracy: 0.6447 - val_loss: 0.3500 - val_accuracy: 0.6500\n"
     ]
    }
   ],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "\n",
    "m=model.fit(X_train, y_train, validation_split=0.2, epochs=30, callbacks=[early_stopping_monitor])\n",
    "#m=model.fit(X_train, y_train, validation_split=0.2, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como constatado pelos testes feitos utilizando os diferentes modelos de machine learning, o modelo que teve a melhor performance foi o svm e o pior modelo foi o do deep learning tendo aproximadamente uma accuracy de apenas 64%.<br>\n",
    "Acreditamos que o modelo de deep learning não teve grande êxito por termos usado um dataset com muito poucos dados, sendo o deep learning mas efetivo em datasets com uma grande quantidade de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
